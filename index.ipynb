{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBERCOREAI COMPANY ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Collection: Gather historical data on stock prices, trading volumes, and other relevant technical indicators for the NYSE and LSE. This data will be sourced from reputable financial databases and APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### I have the relevant technical indicators such as moving averages, RSI, MACD etc ,calculate those from the available price data.I'll proceed with calculating some common technical indicators from the historical stock price data in the LSE and NYSE datasets, including:\n",
    "\n",
    "###### 1. Moving Averages (SMA & EMA)\n",
    "###### 2. Relative Strength Index (RSI)\n",
    "###### 3. Moving Average Convergence Divergence (MACD)\n",
    "###### 4. Bollinger Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         Date        Open        High         Low       Close   Adj Close  \\\n",
       " 0  2001-07-20  392.255005  392.255005  392.255005  392.255005  275.853577   \n",
       " 1  2001-07-23  370.760986  393.597992  365.388000  373.984985  263.005219   \n",
       " 2  2001-07-24  374.523010  374.523010  356.252991  356.790985  250.913574   \n",
       " 3  2001-07-25  349.268005  350.665009  333.148010  343.894989  241.844330   \n",
       " 4  2001-07-26  348.192993  348.192993  340.670990  344.968994  242.599701   \n",
       " \n",
       "       Volume  \n",
       " 0   584009.0  \n",
       " 1  3205437.0  \n",
       " 2   790321.0  \n",
       " 3  1381718.0  \n",
       " 4  1381718.0  ,\n",
       "   ticker        date     open     high      low    close\n",
       " 0      A  1999-11-18  29.5594  32.4842  25.9889  28.5858\n",
       " 1      A  1999-11-19  27.8972  27.9371  25.8613  26.2311\n",
       " 2      A  1999-11-22  26.8370  28.5858  26.0278  28.5858\n",
       " 3      A  1999-11-23  27.6102  28.3377  25.9889  25.9889\n",
       " 4      A  1999-11-24  26.0637  27.2445  25.9889  26.6745)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "lse_data = pd.read_csv('LSE Dataset.csv')\n",
    "nyse_data = pd.read_csv('NYSE Dataset.csv')\n",
    "\n",
    "# the first few rows of each dataset\n",
    "lse_data.head(), nyse_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The datasets contain relevant columns such as Date, Open, High, Low, Close, and Volume, which are important for calculating the technical indicators. I'll now proceed with the following:\n",
    "\n",
    "###### 1. Calculate Moving Averages (SMA & EMA).\n",
    "###### 2. Calculate the Relative Strength Index (RSI).\n",
    "###### 3. Calculate Moving Average Convergence Divergence (MACD).\n",
    "###### 4. Calculate Bollinger Bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Apply to both datasets\u001b[39;00m\n\u001b[0;32m     35\u001b[0m lse_data \u001b[38;5;241m=\u001b[39m calculate_indicators(lse_data)\n\u001b[1;32m---> 36\u001b[0m nyse_data \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_indicators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnyse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Show the first few rows of the updated datasets\u001b[39;00m\n\u001b[0;32m     39\u001b[0m lse_data\u001b[38;5;241m.\u001b[39mhead(), nyse_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m, in \u001b[0;36mcalculate_indicators\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Moving Averages\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMA_20\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMA_20\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mewm(span\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, adjust\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# RSI (Relative Strength Index)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Close'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "lse_data['Date'] = pd.to_datetime(lse_data['Date'])\n",
    "nyse_data['date'] = pd.to_datetime(nyse_data['date'])\n",
    "\n",
    "# Function to calculate technical indicators\n",
    "def calculate_indicators(df):\n",
    "    df = df.sort_values(by='Date' if 'Date' in df.columns else 'date')\n",
    "    \n",
    "    # Moving Averages\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "    # RSI (Relative Strength Index)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # MACD (Moving Average Convergence Divergence)\n",
    "    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['Bollinger_Upper'] = df['SMA_20'] + (2 * df['Close'].rolling(window=20).std())\n",
    "    df['Bollinger_Lower'] = df['SMA_20'] - (2 * df['Close'].rolling(window=20).std())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply to both datasets\n",
    "lse_data = calculate_indicators(lse_data)\n",
    "nyse_data = calculate_indicators(nyse_data)\n",
    "\n",
    "# Show the first few rows of the updated datasets\n",
    "lse_data.head(), nyse_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The column name for stock prices in the NYSE dataset is lowercase ('close'), while in the LSE dataset it is capitalized ('Close'). I'll adjust the code to handle both cases and recalculate the technical indicators for the NYSE dataset. ​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The technical indicators have been successfully calculated for both datasets.\n",
    "\n",
    "###### 1. Moving Averages: SMA (Simple Moving Average) and EMA (Exponential Moving Average) over a 20-day period.\n",
    "###### 2. RSI (Relative Strength Index): Measures the speed and change of price movements to identify oversold conditions.\n",
    "###### 3. MACD (Moving Average Convergence Divergence): Shows the relationship between two EMAs (12 and 26-day periods).\n",
    "###### 4. Bollinger Bands: Upper and lower bands are set 2 standard deviations from the 20-day SMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Date        Open        High         Low       Close   Adj Close  \\\n",
       " 0 2001-07-20  392.255005  392.255005  392.255005  392.255005  275.853577   \n",
       " 1 2001-07-23  370.760986  393.597992  365.388000  373.984985  263.005219   \n",
       " 2 2001-07-24  374.523010  374.523010  356.252991  356.790985  250.913574   \n",
       " 3 2001-07-25  349.268005  350.665009  333.148010  343.894989  241.844330   \n",
       " 4 2001-07-26  348.192993  348.192993  340.670990  344.968994  242.599701   \n",
       " \n",
       "       Volume  SMA_20      EMA_20  RSI      EMA_12      EMA_26      MACD  \\\n",
       " 0   584009.0     NaN  392.255005  NaN  392.255005  392.255005  0.000000   \n",
       " 1  3205437.0     NaN  390.515003  NaN  389.444233  390.901670 -1.457437   \n",
       " 2   790321.0     NaN  387.303192  NaN  384.420656  388.374953 -3.954297   \n",
       " 3  1381718.0     NaN  383.169077  NaN  378.185938  385.080141 -6.894203   \n",
       " 4  1381718.0     NaN  379.530974  NaN  373.075639  382.108945 -9.033306   \n",
       " \n",
       "    Signal_Line  Bollinger_Upper  Bollinger_Lower  \n",
       " 0     0.000000              NaN              NaN  \n",
       " 1    -0.291487              NaN              NaN  \n",
       " 2    -1.024049              NaN              NaN  \n",
       " 3    -2.198080              NaN              NaN  \n",
       " 4    -3.565125              NaN              NaN  ,\n",
       "   ticker       date     open     high      low    Close  SMA_20     EMA_20  \\\n",
       " 0      A 1999-11-18  29.5594  32.4842  25.9889  28.5858     NaN  28.585800   \n",
       " 1      A 1999-11-19  27.8972  27.9371  25.8613  26.2311     NaN  28.361543   \n",
       " 2      A 1999-11-22  26.8370  28.5858  26.0278  28.5858     NaN  28.382901   \n",
       " 3      A 1999-11-23  27.6102  28.3377  25.9889  25.9889     NaN  28.154901   \n",
       " 4      A 1999-11-24  26.0637  27.2445  25.9889  26.6745     NaN  28.013910   \n",
       " \n",
       "    RSI     EMA_12     EMA_26      MACD  Signal_Line  Bollinger_Upper  \\\n",
       " 0  NaN  28.585800  28.585800  0.000000     0.000000              NaN   \n",
       " 1  NaN  28.223538  28.411378 -0.187839    -0.037568              NaN   \n",
       " 2  NaN  28.279271  28.424298 -0.145027    -0.059060              NaN   \n",
       " 3  NaN  27.926906  28.243898 -0.316992    -0.110646              NaN   \n",
       " 4  NaN  27.734228  28.127646 -0.393418    -0.167200              NaN   \n",
       " \n",
       "    Bollinger_Lower  \n",
       " 0              NaN  \n",
       " 1              NaN  \n",
       " 2              NaN  \n",
       " 3              NaN  \n",
       " 4              NaN  )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust column name\n",
    "nyse_data.rename(columns={'close': 'Close'}, inplace=True)\n",
    "\n",
    "# Recalculate indicators for NYSE dataset\n",
    "nyse_data = calculate_indicators(nyse_data)\n",
    "\n",
    "# Show the first few rows of the updated datasets\n",
    "lse_data.head(), nyse_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preprocessing: Clean and preprocess the data by handling missing values, outliers, and performing necessary transformations to prepare the data for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Handle missing values: Fill or drop missing values, depending on the context.\n",
    "###### 2. Outlier detection: Identify and handle outliers using methods such as Z-score or IQR.\n",
    "###### 3. Feature scaling: Normalize or standardize the features if necessary.\n",
    "###### 4. Transformations: Convert dates into numerical values or extract useful features if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Date                0\n",
       " Open                1\n",
       " High                1\n",
       " Low                 1\n",
       " Close               1\n",
       " Adj Close           1\n",
       " Volume              1\n",
       " SMA_20             39\n",
       " EMA_20              0\n",
       " RSI                13\n",
       " EMA_12              0\n",
       " EMA_26              0\n",
       " MACD                0\n",
       " Signal_Line         0\n",
       " Bollinger_Upper    39\n",
       " Bollinger_Lower    39\n",
       " dtype: int64,\n",
       " ticker              0\n",
       " date                0\n",
       " open                0\n",
       " high                0\n",
       " low                 0\n",
       " Close               0\n",
       " SMA_20             19\n",
       " EMA_20              0\n",
       " RSI                13\n",
       " EMA_12              0\n",
       " EMA_26              0\n",
       " MACD                0\n",
       " Signal_Line         0\n",
       " Bollinger_Upper    19\n",
       " Bollinger_Lower    19\n",
       " dtype: int64,\n",
       " Open                0\n",
       " High                0\n",
       " Low                 0\n",
       " Close               0\n",
       " Adj Close           0\n",
       " Volume              0\n",
       " SMA_20              0\n",
       " EMA_20              0\n",
       " RSI                 0\n",
       " EMA_12              0\n",
       " EMA_26              0\n",
       " MACD               73\n",
       " Signal_Line        67\n",
       " Bollinger_Upper     0\n",
       " Bollinger_Lower     0\n",
       " dtype: int64,\n",
       " open                 2\n",
       " high                 0\n",
       " low                  5\n",
       " Close                3\n",
       " SMA_20               0\n",
       " EMA_20               0\n",
       " RSI                  0\n",
       " EMA_12               0\n",
       " EMA_26               0\n",
       " MACD               144\n",
       " Signal_Line        132\n",
       " Bollinger_Upper      0\n",
       " Bollinger_Lower      0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in both datasets\n",
    "missing_lse = lse_data.isnull().sum()\n",
    "missing_nyse = nyse_data.isnull().sum()\n",
    "\n",
    "# Check for outliers in the numerical columns (using Z-score method)\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate Z-scores for numeric columns to identify outliers\n",
    "lse_data_numeric = lse_data.select_dtypes(include=np.number)\n",
    "nyse_data_numeric = nyse_data.select_dtypes(include=np.number)\n",
    "\n",
    "lse_zscores = np.abs(zscore(lse_data_numeric))\n",
    "nyse_zscores = np.abs(zscore(nyse_data_numeric))\n",
    "\n",
    "# Define a threshold for outliers (e.g., Z-score > 3)\n",
    "outliers_lse = (lse_zscores > 3).sum(axis=0)\n",
    "outliers_nyse = (nyse_zscores > 3).sum(axis=0)\n",
    "\n",
    "missing_lse, missing_nyse, outliers_lse, outliers_nyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering: Extract relevant features from the data that can help improve the model's predictive power. This may include technical indicators such as moving averages, relative strength index (RSI), and Bollinger Bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### For feature engineering, I'll extract and prepare the relevant features from the data, focusing on the technical indicators I calculated:\n",
    "\n",
    "###### 1. Moving Averages (SMA and EMA)\n",
    "###### 2. RSI (Relative Strength Index)\n",
    "###### 3. MACD (Moving Average Convergence Divergence)\n",
    "###### 4. Bollinger Bands\n",
    "\n",
    "###### These features will be used as inputs for the predictive model. I will focus on the following steps:\n",
    "\n",
    "###### 1. Extracting only the features that are most relevant for prediction.\n",
    "###### 2. Check that all features are aligned for both the LSE and NYSE datasets.\n",
    "###### 3. Creating a target variable, which may be the next day's stock price or price change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_7208\\3139717693.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['Target'] = df['Close'].shift(-1)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract features for both datasets\u001b[39;00m\n\u001b[0;32m     14\u001b[0m lse_features \u001b[38;5;241m=\u001b[39m extract_features(lse_data)\n\u001b[1;32m---> 15\u001b[0m nyse_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnyse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Display the features\u001b[39;00m\n\u001b[0;32m     18\u001b[0m lse_features\u001b[38;5;241m.\u001b[39mhead(), nyse_features\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(df):\n\u001b[1;32m----> 3\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSMA_20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEMA_20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRSI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMACD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSignal_Line\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBollinger_Upper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBollinger_Lower\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Creating target variable: next day's Close price (next day's prediction)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Date'] not in index\""
     ]
    }
   ],
   "source": [
    "# Feature extraction for model input\n",
    "def extract_features(df):\n",
    "    features = df[['Date', 'SMA_20', 'EMA_20', 'RSI', 'MACD', 'Signal_Line', 'Bollinger_Upper', 'Bollinger_Lower']]\n",
    "    \n",
    "    # Creating target variable: next day's Close price (next day's prediction)\n",
    "    features['Target'] = df['Close'].shift(-1)\n",
    "    \n",
    "    # Drop rows with NaN target (because the last row has no target)\n",
    "    features = features.dropna()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features for both datasets\n",
    "lse_features = extract_features(lse_data)\n",
    "nyse_features = extract_features(nyse_data)\n",
    "\n",
    "# Display the features\n",
    "lse_features.head(), nyse_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  I noticed that the NYSE dataset has the date column in lowercase, while the LSE dataset has the Date column with an uppercase \"D\". I'll adjust for this discrepancy in the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_7208\\3004928171.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['Target'] = df['Close'].shift(-1)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_7208\\3004928171.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['Target'] = df['Close'].shift(-1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(         Date      SMA_20      EMA_20        RSI      MACD  Signal_Line  \\\n",
       " 19 2001-08-16  377.115401  384.698800  76.991105  2.802785    -0.011939   \n",
       " 20 2001-08-17  377.357201  385.879010  76.576404  3.392145     0.668877   \n",
       " 21 2001-08-20  378.270702  386.486248  69.564999  3.429459     1.220994   \n",
       " 22 2001-08-21  380.312552  387.547366  70.338762  3.848226     1.746440   \n",
       " 23 2001-08-22  382.999202  388.507426  64.285293  4.132465     2.223645   \n",
       " \n",
       "     Bollinger_Upper  Bollinger_Lower      Target  \n",
       " 19       409.820331       344.410471  397.091003  \n",
       " 20       410.600504       344.113897  392.255005  \n",
       " 21       412.122359       344.419044  397.627991  \n",
       " 22       413.631215       346.993889  397.627991  \n",
       " 23       412.387195       353.611209  395.479004  ,\n",
       "          Date     SMA_20     EMA_20        RSI      MACD  Signal_Line  \\\n",
       " 19 1999-12-16  28.283215  28.659844  67.898652  0.241679     0.142963   \n",
       " 20 1999-12-17  28.346240  28.772840  61.039735  0.304534     0.175277   \n",
       " 21 1999-12-20  28.557550  28.933265  62.897012  0.399050     0.220032   \n",
       " 22 1999-12-21  28.642655  29.062278  60.400407  0.455040     0.267033   \n",
       " 23 1999-12-22  28.888045  29.236985  59.843124  0.542286     0.322084   \n",
       " \n",
       "     Bollinger_Upper  Bollinger_Lower   Target  \n",
       " 19        30.924960        25.641470  29.8463  \n",
       " 20        31.077024        25.615456  30.4573  \n",
       " 21        31.253017        25.862083  30.2879  \n",
       " 22        31.447154        25.838156  30.8967  \n",
       " 23        31.571082        26.205008  32.3168  )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize date column names to 'Date' for both datasets\n",
    "lse_data.rename(columns={'Date': 'Date'}, inplace=True)\n",
    "nyse_data.rename(columns={'date': 'Date'}, inplace=True)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(df):\n",
    "    features = df[['Date', 'SMA_20', 'EMA_20', 'RSI', 'MACD', 'Signal_Line', 'Bollinger_Upper', 'Bollinger_Lower']]\n",
    "    \n",
    "    # Creating target variable: next day's Close price (next day's prediction)\n",
    "    features['Target'] = df['Close'].shift(-1)\n",
    "    \n",
    "    # Drop rows with NaN target (because the last row has no target)\n",
    "    features = features.dropna()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features for both datasets\n",
    "lse_features = extract_features(lse_data)\n",
    "nyse_features = extract_features(nyse_data)\n",
    "\n",
    "# Display the features\n",
    "lse_features.head(), nyse_features.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Selection: Choose a suitable machine learning algorithm for this problem, such as a recurrent neural network (RNN), long short-term memory (LSTM) network, or a gradient boosting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Normalizes the stock data to a range between 0 and 1 using MinMaxScaler, which helps the LSTM model perform better. Then, it creates sequences of past stock data to predict future stock prices. These input features are paired with the target values (next day's stock price). This prepares the data in a format which is suitable for training an LSTM model, allowing it to learn patterns in the stock data over time. The final result is a dataset ready for model training with input sequences (X) and their corresponding targets (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4324, 60, 7), (4324,), (6217, 60, 7), (6217,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the data using MinMaxScaler (since LSTM models benefit from scaled data)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Normalize features for LSE and NYSE datasets\n",
    "lse_features_scaled = scaler.fit_transform(lse_features[['SMA_20', 'EMA_20', 'RSI', 'MACD', 'Signal_Line', 'Bollinger_Upper', 'Bollinger_Lower']])\n",
    "nyse_features_scaled = scaler.fit_transform(nyse_features[['SMA_20', 'EMA_20', 'RSI', 'MACD', 'Signal_Line', 'Bollinger_Upper', 'Bollinger_Lower']])\n",
    "\n",
    "# Prepare data for LSTM (create sequences)\n",
    "def create_sequences(features_scaled, target, sequence_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(features_scaled)):\n",
    "        X.append(features_scaled[i-sequence_length:i])\n",
    "        y.append(target[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# For LSE and NYSE, create sequences for input and output\n",
    "lse_X, lse_y = create_sequences(lse_features_scaled, lse_features['Target'].values)\n",
    "nyse_X, nyse_y = create_sequences(nyse_features_scaled, nyse_features['Target'].values)\n",
    "\n",
    "# Check the shape of the prepared data\n",
    "lse_X.shape, lse_y.shape, nyse_X.shape, nyse_y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training: Train the selected model using the preprocessed data, with a suitable split between training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The data is split into 80% training and 20% validation sets to evaluation of the model's performance.\n",
    "###### An LSTM model is built with two LSTM layers and dropout layers to prevent overfitting.\n",
    "###### The model is compiled using the Adam optimizer and mean squared error (MSE) loss function for regression tasks.\n",
    "###### The model is trained for 20 epochs with a batch size of 32, using the training data and validating on a separate validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "109/109 [==============================] - 17s 84ms/step - loss: 1082454.3750 - val_loss: 11602088.0000\n",
      "Epoch 2/20\n",
      "109/109 [==============================] - 7s 64ms/step - loss: 1068537.2500 - val_loss: 11562047.0000\n",
      "Epoch 3/20\n",
      "109/109 [==============================] - 8s 71ms/step - loss: 1058200.0000 - val_loss: 11523916.0000\n",
      "Epoch 4/20\n",
      "109/109 [==============================] - 7s 61ms/step - loss: 1048282.3750 - val_loss: 11486574.0000\n",
      "Epoch 5/20\n",
      "109/109 [==============================] - 7s 61ms/step - loss: 1038449.5000 - val_loss: 11449679.0000\n",
      "Epoch 6/20\n",
      "109/109 [==============================] - 7s 61ms/step - loss: 1028721.5000 - val_loss: 11413363.0000\n",
      "Epoch 7/20\n",
      "109/109 [==============================] - 7s 61ms/step - loss: 1019489.6250 - val_loss: 11377503.0000\n",
      "Epoch 8/20\n",
      "109/109 [==============================] - 7s 61ms/step - loss: 1010113.5625 - val_loss: 11341700.0000\n",
      "Epoch 9/20\n",
      "109/109 [==============================] - 7s 67ms/step - loss: 1001010.7500 - val_loss: 11306035.0000\n",
      "Epoch 10/20\n",
      "109/109 [==============================] - 9s 79ms/step - loss: 991786.1875 - val_loss: 11270416.0000\n",
      "Epoch 11/20\n",
      "109/109 [==============================] - 7s 64ms/step - loss: 983102.6875 - val_loss: 11235259.0000\n",
      "Epoch 12/20\n",
      "109/109 [==============================] - 7s 68ms/step - loss: 974064.3125 - val_loss: 11200347.0000\n",
      "Epoch 13/20\n",
      "109/109 [==============================] - 7s 62ms/step - loss: 965216.3750 - val_loss: 11165496.0000\n",
      "Epoch 14/20\n",
      "109/109 [==============================] - 7s 62ms/step - loss: 956072.4375 - val_loss: 11130547.0000\n",
      "Epoch 15/20\n",
      "109/109 [==============================] - 7s 61ms/step - loss: 947235.6250 - val_loss: 11095877.0000\n",
      "Epoch 16/20\n",
      "109/109 [==============================] - 7s 64ms/step - loss: 938674.9375 - val_loss: 11061472.0000\n",
      "Epoch 17/20\n",
      "109/109 [==============================] - 7s 63ms/step - loss: 930457.0000 - val_loss: 11026930.0000\n",
      "Epoch 18/20\n",
      "109/109 [==============================] - 7s 65ms/step - loss: 921660.5625 - val_loss: 10992560.0000\n",
      "Epoch 19/20\n",
      "109/109 [==============================] - 7s 62ms/step - loss: 912967.6875 - val_loss: 10958496.0000\n",
      "Epoch 20/20\n",
      "109/109 [==============================] - 7s 65ms/step - loss: 905319.3750 - val_loss: 10924581.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "lse_X_train, lse_X_val, lse_y_train, lse_y_val = train_test_split(lse_X, lse_y, test_size=0.2, shuffle=False)\n",
    "nyse_X_train, nyse_X_val, nyse_y_train, nyse_y_val = train_test_split(nyse_X, nyse_y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add LSTM layers\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(lse_X_train.shape[1], lse_X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer \n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(lse_X_train, lse_y_train, epochs=20, batch_size=32, validation_data=(lse_X_val, lse_y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation: Evaluate the performance of the trained model using metrics such as mean absolute error (MAE), mean squared error (MSE), and R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Mean Absolute Error (MAE): Measures the average magnitude of errors in the model's predictions, giving an idea of how far off the predictions are, on average.\n",
    "###### 2. Mean Squared Error (MSE): Squares the errors to penalize larger errors more heavily, providing a measure of how well the model is fitting the data.\n",
    "###### 3. R-Squared (R²): Measures the proportion of variance in the data that the model explains, with a higher value indicating better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 3s 20ms/step\n",
      "Mean Absolute Error (MAE): 3224.9298897532217\n",
      "Mean Squared Error (MSE): 10924581.53104432\n",
      "R-Squared (R²): -19.832188146963134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Predict the stock prices using the trained model on the validation data\n",
    "lse_y_pred = model.predict(lse_X_val)\n",
    "\n",
    "# Evaluate the model using MAE, MSE, and R²\n",
    "mae = mean_absolute_error(lse_y_val, lse_y_pred)\n",
    "mse = mean_squared_error(lse_y_val, lse_y_pred)\n",
    "r2 = r2_score(lse_y_val, lse_y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-Squared (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning: Perform hyperparameter tuning to optimize the model's performance, using techniques such as grid search, random search, or Bayesian optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Hyperparameter tuning for an LSTM model using RandomizedSearchCV from Scikit-learn, defines a build_model function that constructs an LSTM model with adjustable parameters, including the number of LSTM units, dropout rate, batch size, number of epochs, and optimizer type. By evaluating different combinations of hyperparameters, it identifies the best set that improves the model's performance. Finally, the code outputs the best hyperparameters, allowing to optimize the model for better predictive accuracy on the stock price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\program files\\python38\\lib\\site-packages (0.12.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\program files\\python38\\lib\\site-packages (from scikeras) (23.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\program files\\python38\\lib\\site-packages (from scikeras) (1.3.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem<0.32,>=0.23.1 in c:\\program files\\python38\\lib\\site-packages (from scikeras) (0.28.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\program files\\python38\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\program files\\python38\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\program files\\python38\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\python38\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.2, model__units=50, optimizer=adam; total time= 1.8min\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.2, model__units=50, optimizer=adam; total time= 1.6min\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.2, model__units=50, optimizer=adam; total time= 1.6min\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__units=150, optimizer=adam; total time= 8.7min\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__units=150, optimizer=adam; total time= 8.6min\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__units=150, optimizer=adam; total time=10.3min\n",
      "[CV] END batch_size=64, epochs=30, model__dropout_rate=0.2, model__units=100, optimizer=adam; total time= 4.7min\n",
      "[CV] END batch_size=64, epochs=30, model__dropout_rate=0.2, model__units=100, optimizer=adam; total time= 2.3min\n",
      "[CV] END batch_size=64, epochs=30, model__dropout_rate=0.2, model__units=100, optimizer=adam; total time= 3.9min\n",
      "[CV] END batch_size=16, epochs=20, model__dropout_rate=0.4, model__units=150, optimizer=rmsprop; total time= 7.6min\n",
      "[CV] END batch_size=16, epochs=20, model__dropout_rate=0.4, model__units=150, optimizer=rmsprop; total time= 5.6min\n",
      "[CV] END batch_size=16, epochs=20, model__dropout_rate=0.4, model__units=150, optimizer=rmsprop; total time=722.8min\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.4, model__units=50, optimizer=adam; total time= 1.9min\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.4, model__units=50, optimizer=adam; total time= 1.7min\n",
      "[CV] END batch_size=32, epochs=20, model__dropout_rate=0.4, model__units=50, optimizer=adam; total time= 2.3min\n",
      "[CV] END batch_size=32, epochs=30, model__dropout_rate=0.3, model__units=150, optimizer=adam; total time=54.5min\n",
      "[CV] END batch_size=32, epochs=30, model__dropout_rate=0.3, model__units=150, optimizer=adam; total time=1062.3min\n",
      "[CV] END batch_size=32, epochs=30, model__dropout_rate=0.3, model__units=150, optimizer=adam; total time=20.1min\n",
      "[CV] END batch_size=16, epochs=10, model__dropout_rate=0.3, model__units=100, optimizer=rmsprop; total time= 3.8min\n",
      "[CV] END batch_size=16, epochs=10, model__dropout_rate=0.3, model__units=100, optimizer=rmsprop; total time= 3.5min\n",
      "[CV] END batch_size=16, epochs=10, model__dropout_rate=0.3, model__units=100, optimizer=rmsprop; total time= 4.7min\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__units=50, optimizer=adam; total time= 1.5min\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__units=50, optimizer=adam; total time= 1.7min\n",
      "[CV] END batch_size=64, epochs=20, model__dropout_rate=0.3, model__units=50, optimizer=adam; total time= 1.6min\n",
      "[CV] END batch_size=32, epochs=30, model__dropout_rate=0.4, model__units=100, optimizer=adam; total time= 5.5min\n",
      "[CV] END batch_size=32, epochs=30, model__dropout_rate=0.4, model__units=100, optimizer=adam; total time= 7.7min\n",
      "[CV] END batch_size=32, epochs=30, model__dropout_rate=0.4, model__units=100, optimizer=adam; total time= 7.6min\n",
      "[CV] END batch_size=64, epochs=30, model__dropout_rate=0.3, model__units=100, optimizer=rmsprop; total time= 3.5min\n",
      "[CV] END batch_size=64, epochs=30, model__dropout_rate=0.3, model__units=100, optimizer=rmsprop; total time= 5.6min\n",
      "[CV] END batch_size=64, epochs=30, model__dropout_rate=0.3, model__units=100, optimizer=rmsprop; total time= 5.1min\n",
      "Best Hyperparameters: {'optimizer': 'rmsprop', 'model__units': 150, 'model__dropout_rate': 0.4, 'epochs': 20, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "\n",
    "# Function to build the Keras model\n",
    "def build_model(units=50, dropout_rate=0.2, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(lse_X_train.shape[1], lse_X_train.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Define the parameter grid for Random Search\n",
    "param_dist = {\n",
    "    'model__units': [50, 100, 150],\n",
    "    'model__dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [10, 20, 30],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Wrap the Keras model using scikeras KerasRegressor\n",
    "model = KerasRegressor(model=build_model, verbose=0)\n",
    "\n",
    "# Perform Random Search with 3-fold cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3, verbose=2)\n",
    "\n",
    "# Assuming lse_X_train and lse_y_train are defined\n",
    "random_search_result = random_search.fit(lse_X_train, lse_y_train)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(f\"Best Hyperparameters: {random_search_result.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\program files\\python38\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: tensorflow in c:\\program files\\python38\\lib\\site-packages (2.11.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\python38\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python38\\lib\\site-packages (1.23.1)\n",
      "Requirement already satisfied: pandas in c:\\program files\\python38\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\program files\\python38\\lib\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\program files\\python38\\lib\\site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\program files\\python38\\lib\\site-packages (from flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\program files\\python38\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\program files\\python38\\lib\\site-packages (from flask) (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\program files\\python38\\lib\\site-packages (from flask) (6.8.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.1 in c:\\program files\\python38\\lib\\site-packages (from tensorflow) (2.11.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (75.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (0.28.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\program files\\python38\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\program files\\python38\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\python38\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python38\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python38\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\program files\\python38\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python38\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\program files\\python38\\lib\\site-packages (from importlib-metadata>=3.6.0->flask) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python38\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\program files\\python38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.1->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\program files\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\program files\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\program files\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\program files\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\program files\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\program files\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask tensorflow scikit-learn numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Deployment: Deploy the final model in a production-ready environment, where it can be used to generate predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model after RandomizedSearchCV\n",
    "best_model = random_search_result.best_estimator_.model_\n",
    "best_model.save(\"./best_lstm_model.h5\")  # Save the model in the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\OneDrive\\Desktop\\CbercoreIT Company\n",
      "['app.py', 'best_lstm_model.h5', 'index.ipynb', 'LSE Dataset.csv', 'NYSE Dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Checking current working directory\n",
    "print(os.listdir(\"./\"))  # List files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 11s 84ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(\"./best_lstm_model.h5\")\n",
    "\n",
    "# Predict using the loaded model\n",
    "predictions = loaded_model.predict(lse_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "print(type(best_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
